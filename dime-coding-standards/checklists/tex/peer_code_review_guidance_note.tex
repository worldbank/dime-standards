
\documentclass{tufte-handout}
\input{checklist-header}


\begin{document}
\thispagestyle{firstpage}
	\begin{fullwidth}

\titleBox{
	\textcolor{white}{\LARGE{\textbf{DIME Analytics \\ Peer Code Review Guidance Note}} \\
	}
}

\section*{Overview}
DIME Analytics organizes the \textbf{Peer Code Review} as a real-time code and data-quality assurance process, providing a structured opportunity for participants to exchange, run, and provide feedback on each other's code. Beyond improving reproducibility, transparency, and adherence to best practices, it is also a valuable learning experience—code writers gain fresh perspectives on their work, while reviewers are exposed to different coding styles and practices.

\vspace{5mm}
\noindent The Peer Code Review is especially beneficial for \textbf{new Research Assistants}, as it helps them understand expectations and learn from others' code.

\vspace{5mm}
\noindent The review is designed for scripts that are modular enough to be understood on their own (i.e., a reviewer can follow the script without referring to other project files) and short enough to be reviewed \textbf{within one day} (depending on complexity). If participants wish to submit longer scripts, they will be paired with others submitting similarly long code to ensure a balanced review process. We recommend submitting recently completed tasks to allow for timely corrections and improvements.

\vspace{5mm}
\noindent The time commitment for each round is \textbf{8-10 hours}, including two dedicated sessions that participants are expected to attend.

\section*{How It Works}

\begin{enumerate}
    \item Teams \href{https://survey.wb.surveycto.com/collect/code_review_sign_up?caseid=}{sign up} to participate in the code review.
    \begin{itemize}
        \item All DIME Research Assistants working on code are expected to participate regularly.
        \item Any Bank staff or consultant seeking feedback on their code is welcome to join.
    \end{itemize}
    \item Participants are paired for the review based on their preferred statistical software and the length of their code.
    \item All participants prepare a code package to share with their assigned code review partners, following \href{https://github.com/worldbank/dime-standards/blob/master/dime-coding-standards/checklists/Peer%20Code%20Review%20Submission%20Checklist.pdf}{this checklist}.
    \begin{itemize}
        \item Submitted code should ideally be \textbf{around 1,000 lines}, excluding the main scripts (\href{https://github.com/worldbank/wb-reproducible-research-repository/blob/main/resources/main.do}{Stata}, \href{https://github.com/worldbank/wb-reproducible-research-repository/blob/main/resources/main.R}{R}).
        \item This is a recommendation rather than a strict limit—longer submissions are allowed but may require more time to review.
        \item Teams should specify which aspects of their code they would like reviewed, such as: Data cleaning, Indicator construction, Analysis, Sampling and randomization, High-frequency checks, etc.
        \item Teams should also indicate whether they want the reviewer to assess \textbf{computational reproducibility}.
        \item To enable reproducibility checks, the submission package \textbf{must} include a \textbf{de-identified dataset}.
    \end{itemize}
    \item The \textbf{peer code review} takes place over the course of one week and includes:
    \begin{itemize}
        \item A \textbf{hybrid kickoff session} outlining the process and assigning code review partners. Attendance is \textbf{optional} for those who have participated before.
        \item A \textbf{hybrid group review session} with technical support from DIME Analytics.
        \begin{itemize}
            \item Pairs work together, reviewing each other's code and addressing questions.
            \item Attendance is \textbf{mandatory}—if the scheduled session is not feasible, Analytics will facilitate an alternative meeting.
        \end{itemize}
        \item This activity is most effective when teams can collaborate \textbf{in person}, allowing for real-time discussions and clarifications.
    \end{itemize}
    \item Reviewers assess the code using the following resources:
    \begin{itemize}
        \item \textbf{General:} \href{https://github.com/worldbank/dime-standards/blob/master/dime-coding-standards/checklists/Reviewer%20Feedback%20Checklist.pdf}{Main Feedback Checklist}
        \item \textbf{Task-Specific Checklists:}
        \begin{itemize}
            \item \href{https://github.com/worldbank/dime-standards/blob/d9111654531319fe96095d4bf0acf7fa0b66bacd/dime-coding-standards/checklists/Cleaning%20Code%20Review%20Checklist.pdf}{Cleaning Code Review Checklist}
            \item \href{https://github.com/worldbank/dime-standards/blob/d9111654531319fe96095d4bf0acf7fa0b66bacd/dime-coding-standards/checklists/Construction%20Code%20Review%20Checklist.pdf}{Indicator Construction Checklist}
            \item \href{https://github.com/worldbank/dime-standards/blob/d9111654531319fe96095d4bf0acf7fa0b66bacd/dime-coding-standards/checklists/Analysis%20Code%20Review%20Checklist.pdf}{Analysis Code Review Checklist}
            \item \href{https://github.com/worldbank/dime-standards/blob/d9111654531319fe96095d4bf0acf7fa0b66bacd/dime-coding-standards/checklists/Sampling%20and%20Random%20Treatment%20Assignment%20Checklist.pdf}{Sampling \& Randomization Checklist}
            \item \href{https://github.com/worldbank/dime-standards/blob/d9111654531319fe96095d4bf0acf7fa0b66bacd/dime-coding-standards/checklists/HFCs%20Checklist.pdf}{High-Frequency Checks Checklist}
        \end{itemize}
    \end{itemize}
    \item Reviewers have one week to submit feedback using \href{https://survey.wb.surveycto.com/collect/code_review_summary?caseid=}{this form} and upload their completed task-specific checklists.
\end{enumerate}

\section*{What Teams Receive}
\begin{itemize}
    \item \textbf{Within 10 days}, TTLs and research assistants receive a \href{https://github.com/worldbank/dime-standards/blob/d9111654531319fe96095d4bf0acf7fa0b66bacd/dime-coding-standards/checklists/samples/Sample%20TTL%20Report.pdf}{standardized report} indicating adherence to best practices and areas for improvement.
    \item Research assistants also receive detailed feedback through the task-specific checklists submitted by the reviewers.
    \item All participating TTLs and DIME Managers receive a \href{https://github.com/worldbank/dime-standards/blob/d9111654531319fe96095d4bf0acf7fa0b66bacd/dime-coding-standards/checklists/samples/Peer%20Code%20Review%20Summary%20-%20FY24%20Q3.pdf}{summary report} highlighting common strengths and weaknesses.
\end{itemize}


	\end{fullwidth}
\end{document}
